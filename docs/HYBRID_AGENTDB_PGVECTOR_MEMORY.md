# Hybrid Memory System: AgentDB + pgvector + Oneiric

**Architecture**: Hot data (AgentDB) + Warm/cold data (pgvector) + GCS backup

**Date**: 2025-01-23
**Status**: ‚úÖ AgentDB adapter created for Oneiric

---

## üéØ Why Hybrid?

**AgentDB = Hot Cache**:
- ‚ö° **Sub-1ms latency** for active agent memory
- üß† **Purpose-built for AI agents** with cognitive patterns
- üîÑ **QUIC synchronization** across nodes
- üìç **In-memory** for blazing-fast access

**pgvector + PostgreSQL = Persistent Archive**:
- üíæ **30+ years of production reliability**
- üîí **Battle-tested backups** (pg_dump + WAL archiving)
- ‚òÅÔ∏è **Well-documented GCS integration**
- üìä **Mature ecosystem** (ORMs, monitoring, GUIs)

**Best of Both Worlds**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Your Application (Mahavishnu)                  ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Oneiric Lifecycle Manager               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ vector: agentdb (primary, hot)      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ vector: pgvector (backup, cold)     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ           ‚îÇ                      ‚îÇ               ‚îÇ
‚îÇ           ‚ñº                      ‚ñº               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  AgentDB     ‚îÇ      ‚îÇ  pgvector   ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  (Hot data)  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (Archive)  ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  - Active    ‚îÇ Sync ‚îÇ  - History  ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  - Recent    ‚îÇ      ‚îÇ  - Backups  ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                  ‚îÇ               ‚îÇ
‚îÇ                                  ‚ñº               ‚îÇ
‚îÇ                     Google Cloud Storage          ‚îÇ
‚îÇ                     (pg_dump + gsutil)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚úÖ Oneiric AgentDB Adapter Created!

**File**: `/Users/les/Projects/oneiric/oneiric/adapters/vector/agentdb.py`

**Features**:
- ‚úÖ Full `VectorBase` implementation
- ‚úÖ MCP client integration (AgentDB runs as MCP server)
- ‚úÖ Lifecycle hooks (`init()`, `health()`, `cleanup()`)
- ‚úÖ All vector operations (search, insert, upsert, delete, get, count)
- ‚úÖ Collection management
- ‚úÖ Configurable settings (Pydantic V2)
- ‚úÖ Structured logging with Oneiric patterns
- ‚úÖ Registered in `bootstrap.py`

**Capabilities**:
- `vector_search` - Semantic similarity search
- `batch_operations` - Bulk inserts/updates
- `metadata_filtering` - Filter by metadata fields
- `real_time` - Sub-1ms latency
- `quic_sync` - Multi-node synchronization
- `agent_optimized` - Purpose-built for AI agents

---

## üöÄ Setup & Installation

### Step 1: Install AgentDB

```bash
# Install AgentDB via npm (Node.js required)
npm install -g agentdb

# Or use npx (runs without installation)
npx agentdb@latest

# Verify installation
agentdb --version
```

### Step 2: Start AgentDB MCP Server

```bash
# Start AgentDB as MCP server
agentdb mcp start

# Or via npx
npx agentdb@latest mcp start

# Default: stdio://agentdb
# Optional: HTTP server on specific port
agentdb mcp start --port 3000 --transport http
```

### Step 3: Install pgvector + PostgreSQL

```bash
# Install PostgreSQL + pgvector via Homebrew
brew install postgresql@16 pgvector
brew services start postgresql@16

# Initialize database
psql postgres -c "CREATE DATABASE memory_db;"
psql memory_db -c "CREATE EXTENSION vector;"
```

### Step 4: Configure Oneiric

Create `settings/mahavishnu.yaml`:

```yaml
# Mahavishnu configuration with hybrid memory
adapters:
  vector:
    # Primary: AgentDB for hot data
    provider: agentdb
    settings:
      mcp_server_url: "stdio://agentdb"
      in_memory: true
      cache_size_mb: 256
      default_collection: "agent_memory"

    # Backup: pgvector for persistent storage
    backup:
      provider: pgvector
      settings:
        host: "localhost"
        port: 5432
        user: "postgres"
        password: "${POSTGRES_PASSWORD}"
        database: "memory_db"
        default_collection: "agent_archive"

# Storage for GCS backups
storage:
  type: "gcs"
  bucket: "mahavishnu-memory-backup"
  prefix: "agent-memory/"
  credentials:
    type: "service-account"
    path: "/path/to/service-account.json"
```

---

## üêç Python Implementation

### Basic Usage

```python
"""Hybrid memory system with AgentDB + pgvector via Oneiric."""
import asyncio
from oneiric.core.lifecycle import LifecycleManager
from oneiric.core.resolution import Resolver
from oneiric.adapters.vector import VectorDocument


async def hybrid_memory_demo():
    """Demonstrate hybrid AgentDB + pgvector setup."""

    # Initialize Oneiric
    resolver = Resolver()
    lifecycle = LifecycleManager(resolver)

    # Activate AgentDB (primary, hot data)
    agentdb = await lifecycle.activate("adapter", "vector", provider="agentdb")

    # Activate pgvector (backup, cold data)
    pgvector = await lifecycle.activate(
        "adapter", "vector", provider="pgvector"
    )

    # Create collection
    await agentdb.create_collection(
        name="agent_memories",
        dimension=1536,
        distance_metric="cosine",
    )

    # Insert into AgentDB (hot)
    hot_doc = VectorDocument(
        id="mem_1",
        vector=[0.1, 0.2, 0.3, ...],  # Your embedding
        metadata={
            "type": "decision",
            "content": "Chose PostgreSQL for ACID compliance",
            "timestamp": "2025-01-23T10:00:00Z",
        },
    )

    doc_id = await agentdb.insert("agent_memories", [hot_doc])
    print(f"‚úÖ Inserted into AgentDB: {doc_id}")

    # Search from AgentDB (sub-1ms)
    query = [0.15, 0.25, 0.35, ...]
    results = await agentdb.search(
        collection="agent_memories",
        query_vector=query,
        limit=5,
    )
    print(f"‚úÖ Search results from AgentDB: {len(results)} hits")

    # Backup to pgvector (persistent)
    await pgvector.create_collection(
        name="agent_memories",
        dimension=1536,
        distance_metric="cosine",
    )
    await pgvector.insert("agent_memories", [hot_doc])
    print("‚úÖ Backed up to pgvector")

    # Cleanup
    await lifecycle.cleanup_all()


if __name__ == "__main__":
    asyncio.run(hybrid_memory_demo())
```

---

## üîÑ Auto-Sync Strategy

### Option 1: Periodic Sync (Cron/Launchd)

```python
"""Periodic sync from AgentDB to pgvector."""
import asyncio
from datetime import datetime


async def sync_agentdb_to_pgvector():
    """Sync recent memories from AgentDB to pgvector."""

    # Get recent documents from AgentDB
    agentdb = await lifecycle.activate("adapter", "vector", provider="agentdb")
    pgvector = await lifecycle.activate("adapter", "vector", provider="pgvector")

    # Fetch recent docs (last hour)
    recent_docs = await agentdb.get(
        collection="agent_memories",
        ids=[],  # Get all (or use timestamp filter)
        include_vectors=True,
    )

    # Backup to pgvector
    if recent_docs:
        await pgvector.upsert("agent_memories", recent_docs)
        print(f"‚úÖ Synced {len(recent_docs)} memories to pgvector")

    # Backup pgvector to GCS
    await backup_pgvector_to_gcs()


async def backup_pgvector_to_gcs():
    """Backup pgvector database to GCS."""
    import subprocess
    from datetime import datetime

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = f"memory_backup_{timestamp}.sql.gz"

    # pg_dump + gzip
    subprocess.run(
        f"pg_dump -U postgres memory_db | gzip > /tmp/{backup_file}",
        shell=True,
        check=True,
    )

    # Upload to GCS via gsutil
    subprocess.run(
        f"gsutil cp /tmp/{backup_file} gs://mahavishnu-memory-backup/",
        shell=True,
        check=True,
    )

    print(f"‚úÖ Backed up to GCS: {backup_file}")


# Schedule with macOS launchd
# Load: ~/Library/LaunchAgents/com.mahavishnu.memory_sync.plist
# Run: Hourly (3600 seconds)
```

### Option 2: Write-Through Cache

```python
"""Write-through cache: Write to both AgentDB and pgvector."""
async def store_memory_with_backup(
    content: str,
    embedding: list[float],
    metadata: dict,
):
    """Store memory in AgentDB + pgvector simultaneously."""

    agentdb = await lifecycle.activate("adapter", "vector", provider="agentdb")
    pgvector = await lifecycle.activate("adapter", "vector", provider="pgvector")

    doc = VectorDocument(
        vector=embedding,
        metadata={**metadata, "content": content},
    )

    # Write to both (parallel)
    await asyncio.gather(
        agentdb.insert("agent_memories", [doc]),
        pgvector.insert("agent_memories", [doc]),
    )

    print("‚úÖ Stored in AgentDB + pgvector")
```

---

## üìä Configuration Examples

### Development (Local)

```yaml
# settings/local.yaml
adapters:
  vector:
    provider: agentdb
    settings:
      mcp_server_url: "stdio://agentdb"
      in_memory: true  # No persistence
      cache_size_mb: 128

storage:
  type: "local"  # No cloud backup in dev
  path: "./data/memory"
```

### Production (Hybrid + GCS)

```yaml
# settings/production.yaml
adapters:
  vector:
    provider: agentdb
    settings:
      mcp_server_url: "http://agentdb:3000"  # Docker network
      in_memory: true
      cache_size_mb: 512
      sync_enabled: true
      sync_nodes:
        - "agentdb-node2:3000"
        - "agentdb-node3:3000"

    backup:
      provider: pgvector
      settings:
        host: "${POSTGRES_HOST}"
        port: 5432
        user: "${POSTGRES_USER}"
        password: "${POSTGRES_PASSWORD}"
        database: "memory_db"

storage:
  type: "gcs"
  bucket: "mahavishnu-memory-prod"
  prefix: "agent-memory/"
  credentials:
    type: "service-account"
    path: "${GCS_CREDENTIALS_PATH}"
```

---

## üîç Monitoring & Observability

### Health Checks

```python
"""Monitor hybrid memory system health."""
async def check_memory_system_health():
    """Check health of AgentDB + pgvector."""

    lifecycle = LifecycleManager(resolver)

    # Check AgentDB
    agentdb_healthy = await lifecycle.probe_instance_health(
        "adapter", "vector", provider="agentdb"
    )
    print(f"AgentDB: {'‚úÖ Healthy' if agentdb_healthy else '‚ùå Unhealthy'}")

    # Check pgvector
    pgvector_healthy = await lifecycle.probe_instance_health(
        "adapter", "vector", provider="pgvector"
    )
    print(f"pgvector: {'‚úÖ Healthy' if pgvector_healthy else '‚ùå Unhealthy'}")

    return agentdb_healthy and pgvector_healthy
```

### Metrics

```python
"""Track memory system metrics."""
from oneiric.adapters.monitoring import OTLPObservabilityAdapter


async def track_memory_metrics():
    """Export metrics to OpenTelemetry."""

    # Get adapter stats
    agentdb = await lifecycle.activate("adapter", "vector", provider="agentdb")
    pgvector = await lifecycle.activate("adapter", "vector", provider="pgvector")

    # Count documents
    agentdb_count = await agentdb.count("agent_memories")
    pgvector_count = await pgvector.count("agent_memories")

    # Export to OTLP
    otlp = await lifecycle.activate("monitoring", "otlp")
    await otlp.export_metrics(
        {
            "agentdb_document_count": agentdb_count,
            "pgvector_document_count": pgvector_count,
            "sync_lag_seconds": ...,
        }
    )
```

---

## üß™ Testing

```python
"""Test hybrid memory system."""
import pytest
from oneiric.adapters.vector import VectorDocument


@pytest.mark.asyncio
async def test_hybrid_memory_insert_and_search():
    """Test inserting into AgentDB and searching from both."""

    # Insert into AgentDB
    doc = VectorDocument(
        id="test_1",
        vector=[0.1] * 1536,
        metadata={"test": True},
    )

    doc_id = await agentdb.insert("test_collection", [doc])
    assert len(doc_id) == 1

    # Sync to pgvector
    await pgvector.insert("test_collection", [doc])

    # Search from AgentDB (hot)
    agentdb_results = await agentdb.search(
        "test_collection",
        query_vector=[0.1] * 1536,
        limit=1,
    )
    assert len(agentdb_results) == 1
    assert agentdb_results[0].id == "test_1"

    # Search from pgvector (backup)
    pgvector_results = await pgvector.search(
        "test_collection",
        query_vector=[0.1] * 1536,
        limit=1,
    )
    assert len(pgvector_results) == 1
    assert pgvector_results[0].id == "test_1"
```

---

## üí° Best Practices

### 1. When to Use AgentDB (Hot)
- ‚úÖ **Active agent memory** (current session, recent decisions)
- ‚úÖ **Frequently accessed data** (user preferences, active tasks)
- ‚úÖ **Real-time coordination** (multi-agent sync)
- ‚úÖ **Sub-ms latency required**

### 2. When to Use pgvector (Cold)
- ‚úÖ **Long-term storage** (historical decisions, audit trail)
- ‚úÖ **Backup/disaster recovery** (GCS integration)
- ‚úÖ **Analytics and reporting** (SQL queries on metadata)
- ‚úÖ **Compliance and retention** (WAL archiving)

### 3. Sync Strategy
- **Write-through**: Write to both immediately (consistency over latency)
- **Write-back**: Write to AgentDB, async sync to pgvector (latency over consistency)
- **Periodic**: Cron job syncs every N minutes (simple, eventual consistency)

### 4. Data Lifecycle
```
New Memory
    ‚Üì
AgentDB (hot, in-memory)
    ‚Üì (after 1 hour or session end)
pgvector (warm, PostgreSQL)
    ‚Üì (daily backup)
GCS (cold, archived)
```

---

## üîó Resources

- **Oneiric Vector Adapters**: `/Users/les/Projects/oneiric/docs/analysis/VECTOR_ADAPTERS.md`
- **AgentDB Documentation**: [agentdb.ruv.io](https://agentdb.ruv.io/)
- **AgentDB NPM**: [npmjs.com/package/agentdb](https://www.npmjs.com/package/agentdb)
- **Claude Flow (AgentDB integration)**: [github.com/ruvnet/claude-flow](https://github.com/ruvnet/claude-flow)
- **pgvector GitHub**: [github.com/pgvector/pgvector](https://github.com/pgvector/pgvector)

---

## Summary

**‚úÖ AgentDB adapter added to Oneiric!**

**Hybrid Architecture**:
- **AgentDB**: Hot data, sub-1ms access, agent-optimized
- **pgvector**: Persistent archive, GCS backups, SQL queries
- **Oneiric**: Unified lifecycle management for both
- **GCS**: Long-term cloud storage via pg_dump + gsutil

**Benefits**:
- ‚ö° **Blazing fast** active memory (AgentDB)
- üíæ **Production backups** (pgvector + GCS)
- üîÑ **Flexible sync** strategies
- üõ†Ô∏è **Oneiric integration** (lifecycle, health checks, hot-swapping)

**Next Steps**:
1. Install AgentDB (`npm install -g agentdb`)
2. Start AgentDB MCP server
3. Test Oneiric AgentDB adapter
4. Implement sync strategy (write-through or periodic)
5. Set up GCS backups for pgvector

The hybrid approach gives you the **best of both worlds**! üöÄ
