# Mahavishnu Task Orchestration System - Master Plan v3.0

**Status**: APPROVED - 9-Agent Review Complete (5-Agent + 4-Agent Opus)
**Created**: 2026-02-18
**Updated**: 2026-02-18 (Incorporated 5-Agent + 4-Agent Opus Review Feedback)
**Author**: Claude Sonnet 4.5 + User Collaboration
**Version**: 3.1

---

## Executive Summary

The Mahavishnu Task Orchestration System (MTOS) is a natural language-powered task management platform designed for multi-repository software development ecosystems. This version incorporates comprehensive feedback from a 5-agent review council (Security Auditor, Architecture Reviewer, UX Researcher, SRE Engineer, Python Pro).

### 5-Agent Review Council Results

**Overall Council Verdict**: APPROVED WITH CONDITIONS âš ï¸
**Average Score**: 7.04/10 (Good foundation, critical gaps addressed)

| Agent | Score | Status | Critical Issues |
|-------|-------|--------|-----------------|
| **Security Auditor** | 7.5/10 | âœ… APPROVED | 5 P0 security fixes (4.5 days) |
| **Architecture Reviewer** | 4.2/5.0 | âœ… APPROVED | Simplify 4-system â†’ 2-system storage |
| **UX Researcher** | 7.5/10 | âœ… APPROVED | Extend Phase 1 to 6 weeks for UX |
| **SRE Engineer** | 6.5/10 | âœ… APPROVED | Extend Phase 0 to 6-8 weeks, add on-call |
| **Python Pro** | 8.5/10 | âœ… APPROVED | Fix Pydantic v2, async context managers |

### 4-Agent Opus Review Council Results (v3.1)

**Overall Council Verdict**: APPROVED WITH REFINEMENTS âš ï¸
**Average Score**: 7.3/10 (Solid foundation, actionable improvements)

| Agent | Score | Status | Focus Area |
|-------|-------|--------|------------|
| **Delivery Lead** | 7.5/10 | âœ… APPROVED | Timeline feasibility, phase dependencies, risks |
| **AI Engineer** | 6.8/10 | âš ï¸ CONDITIONS | NLP/ML architecture, semantic search, embeddings |
| **DX Lead** | 7.3/10 | âœ… APPROVED | CLI/TUI, onboarding, error handling, accessibility |
| **Code Reviewer** | 7.6/10 | âœ… APPROVED | Pydantic v2, async patterns, security, database |

**Critical P0 Issues Identified by 4-Agent Opus Review**:

1. **Missing Users Table** - Foreign keys reference undefined table (Code Reviewer)
2. **No Error Code System** - Error handling UX is incomplete (DX Lead)
3. **No NLP Model Specification** - Cannot implement without model choice (AI Engineer)
4. **No Async Timeout Handling** - Could cause hanging operations (Code Reviewer)
5. **No Saga Locks for Crash Safety** - Multiple workers could collide (Code Reviewer)
6. **Deliverables Lack Acceptance Criteria** - Cannot determine phase completion (Delivery Lead)
7. **No Tutorial Sandbox Mode** - Risky to use real tasks (DX Lead)

### Key Updates in v3.0

1. **Architecture Simplification**: Reduced from 4-system to 2-system storage (PostgreSQL + optional Redis)
2. **Security Enhancements**: Added replay attack prevention, Pydantic v2 models, task-specific audit logging
3. **SRE Fundamentals**: Added error budget enforcement, disaster recovery testing, on-call procedures
4. **UX Improvements**: Added skip onboarding option, moved accessibility to Phase 1, extended timeline
5. **Python Modernization**: Fixed Pydantic v2 syntax, added async context managers, Protocol definitions

### Key Updates in v3.1 (4-Agent Opus Review)

1. **Error Code System**: Added MHV-001 to MHV-099 error codes with documentation pages
2. **Users Table**: Added users table schema with proper foreign key constraints
3. **Async Patterns**: Added timeout handling, async context managers, cancellation handling
4. **NLP Specification**: Specified structured extraction with Claude/GPT-4 via function calling
5. **Hybrid Retrieval**: Combined vector similarity (pgvector) with lexical matching (PostgreSQL FTS)
6. **Local Embedding Fallback**: Added fastembed/Ollama as fallback for OpenAI embeddings
7. **Saga Crash Safety**: Added SELECT FOR UPDATE for saga crash recovery
8. **Rate Limiting**: Added slowapi rate limiting middleware
9. **Acceptance Criteria**: Added measurable success criteria to all phase deliverables
10. **Missing Risks**: Added AI model dependency, staff turnover, scope creep, webhook rate limiting risks

### Timeline

**Original Timeline (v2.0)**: 24-29 weeks (6-7 months)
**Revised Timeline (v3.0)**: 26-32 weeks (6.5-8 months)

**Timeline Changes**:
- Phase 0: 3-4 weeks â†’ 6-8 weeks (+3-4 weeks for SRE fundamentals)
- Phase 1: 4-5 weeks â†’ 6 weeks (+1-2 weeks for UX polish)
- Net Change: +2 to +4 weeks (worthwhile for robustness)

---

## Table of Contents

1. [Architecture](#architecture)
2. [Security](#security)
3. [SRE & Reliability](#sre--reliability)
4. [User Experience](#user-experience)
5. [Storage Strategy](#storage-strategy)
6. [Implementation Phases](#implementation-phases)
7. [ADRs (Architecture Decision Records)](#adrs)
8. [Appendices](#appendices)

---

## Architecture

### Simplified Storage Architecture (ADR-001)

The v2.0 plan proposed a 4-system storage architecture (PostgreSQL + Akosha + Session-Buddy + Redis). The Architecture Reviewer identified this as P0 critical - too complex for v1.0.

**Decision**: Simplify to 2-system storage (PostgreSQL + optional Redis)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interfaces                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   CLI    â”‚ â”‚   TUI    â”‚ â”‚   GUI    â”‚ â”‚   Web    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚            â”‚            â”‚            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  API Layer (FastAPI)     â”‚
        â”‚  - REST endpoints        â”‚
        â”‚  - WebSocket (real-time) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Orchestrator Layer (Mahavishnu)          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚  NLP Parser      â”‚  â”‚ Task Coordinatorâ”‚ â”‚
        â”‚  â”‚  (Intent         â”‚  â”‚ (Saga Pattern)  â”‚ â”‚
        â”‚  â”‚   Extraction)    â”‚  â”‚                 â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚           â”‚                     â”‚           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚ Pattern Detector â”‚  â”‚ Dependency Mgr  â”‚ â”‚
        â”‚  â”‚ (ML-based)       â”‚  â”‚ (Cross-repo)    â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       Storage Layer (Simplified)              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚ PostgreSQL (Primary + Semantic)       â”‚   â”‚
        â”‚  â”‚ - Tasks, Events, Projections          â”‚   â”‚
        â”‚  â”‚ - Vector embeddings (pgvector)        â”‚   â”‚
        â”‚  â”‚ - Knowledge graph (relationships)     â”‚   â”‚
        â”‚  â”‚ - Pattern detection (ML)              â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚ Session-Buddy (Best-Effort)           â”‚   â”‚
        â”‚  â”‚ - Task context (fire-and-forget)      â”‚   â”‚
        â”‚  â”‚ - Conversation history                â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚ Redis (Optional - Phase 7)            â”‚   â”‚
        â”‚  â”‚ - Cache (add only if proven needed)   â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits**:
- 60% reduction in operational complexity
- Eliminates 2 critical failure modes
- Single source of truth (PostgreSQL)
- Faster development (2 weeks saved)

### Saga Coordinator Pattern (ADR-002)

Multi-step operations (task creation, imports, migrations) require distributed transaction coordination.

**Decision**: Implement persistent SagaCoordinator with crash recovery

```python
class SagaCoordinator:
    """
    Persistent saga coordinator with crash recovery.

    Features:
    - Persistent saga log in PostgreSQL
    - Crash recovery on restart
    - Exponential backoff retry
    - Circuit breaker for failing steps
    - Idempotent step execution
    """

    async def execute_saga(
        self,
        saga_id: str,
        steps: list[SagaStep],
        initial_state: dict[str, Any],
    ) -> SagaResult:
        """
        Execute saga with crash recovery and retry logic.
        """
        # Load or create saga state from PostgreSQL
        saga_state = await self._load_or_create_saga(saga_id, steps, initial_state)

        # Resume from last completed step (crash recovery)
        start_index = saga_state.current_step_index

        # Execute remaining steps with retry logic
        for i in range(start_index, len(steps)):
            step = steps[i]

            try:
                result = await self._execute_step_with_retry(
                    step=step,
                    state=saga_state.state,
                    saga_id=saga_id,
                )

                # Update saga state
                saga_state.state.update(result)
                saga_state.completed_steps.append(i)
                saga_state.current_step_index = i + 1

                # Persist saga state to PostgreSQL
                await self._persist_saga_state(saga_state)

            except Exception as e:
                # Step failed after retries - compensate
                await self._compensate(saga_state, failure_reason=str(e))
                raise SagaExecutionError(f"Saga {saga_id} failed at step {i}: {e}")

        # All steps completed successfully
        saga_state.status = SagaStatus.COMPLETED
        await self._persist_saga_state(saga_state)

        return SagaResult(
            saga_id=saga_id,
            status=SagaStatus.COMPLETED,
            state=saga_state.state,
        )
```

**Simplified Saga for 2-System Architecture**:

```
Saga: Create Task (2 steps - simplified from 4 steps)

Step 1: Create task in PostgreSQL
  âœ“ Success â†’ Continue
  âœ— Failure â†’ Rollback (nothing to undo)

Step 2: Store context in Session-Buddy (best-effort)
  âœ“ Success â†’ Complete
  âœ— Failure â†’ Complete anyway (best-effort, no compensation)
```

---

## Security

### Security Auditor Recommendations (7.5/10)

All 5 P0 security issues from Security Auditor review have been addressed:

### 1. Replay Attack Prevention (P0-1)

**Problem**: Webhooks can be replayed without detection

**Solution**: Add timestamp/nonce validation to webhook signature verification

```python
class WebhookAuthenticator:
    """
    Webhook authentication with replay attack prevention.

    Features:
    - HMAC signature validation
    - Timestamp validation (reject webhooks older than 5 minutes)
    - Nonce/ID tracking (prevent replay attacks)
    """

    async def verify_webhook_signature(
        self,
        payload: bytes,
        signature: str,
        webhook_id: str,
        timestamp: str,
        secret: str,
    ) -> bool:
        """
        Verify webhook signature with replay attack prevention.
        """
        # Step 1: Verify HMAC signature
        hash_algorithm, github_signature = signature.split('=', 1)
        algorithm = hashlib.sha256

        mac = hmac.new(secret.encode(), msg=payload, digestmod=algorithm)
        expected_signature = mac.hexdigest()

        if not hmac.compare_digest(expected_signature, github_signature):
            raise WebhookAuthError("Invalid signature")

        # Step 2: Validate timestamp (prevent old webhooks)
        try:
            webhook_time = datetime.fromisoformat(timestamp)
        except ValueError:
            raise WebhookAuthError("Invalid timestamp format")

        if datetime.now(timezone.utc) - webhook_time > self.max_age:
            raise WebhookAuthError(f"Webhook too old (max age: {self.max_age})")

        # Step 3: Check for replay attack (duplicate webhook_id)
        if await self._was_webhook_processed(webhook_id):
            raise WebhookAuthError(f"Duplicate webhook_id: {webhook_id} (replay attack)")

        # Step 4: Mark webhook as processed
        await self._mark_webhook_processed(webhook_id, timestamp)

        return True
```

### 2. TaskCreateRequest Pydantic Model (P0-2)

**Problem**: Input validation not formalized with Pydantic models

**Solution**: Create comprehensive Pydantic v2 models for all inputs

```python
from pydantic import BaseModel, Field, field_validator
from typing import Literal
import re

class TaskCreateRequest(BaseModel):
    """Task creation request with comprehensive validation."""

    title: str = Field(..., min_length=1, max_length=200)
    description: str | None = Field(None, max_length=5000)
    repository: str = Field(..., min_length=1, max_length=100)
    priority: Literal['low', 'medium', 'high', 'critical'] = 'medium'
    deadline: str | None = None  # ISO 8601 format

    @field_validator('title')
    @classmethod
    def sanitize_title(cls, v: str) -> str:
        """Remove potentially dangerous characters from title."""
        # Remove null bytes
        v = v.replace('\x00', '')

        # Limit length
        if len(v) > 200:
            raise ValueError('Title too long (max 200 characters)')

        # Remove control characters (except newline, tab)
        v = ''.join(c for c in v if c == '\n' or c == '\t' or not c.isascii() or not c.iscntrl())

        return v.strip()

    @field_validator('repository')
    @classmethod
    def validate_repository(cls, v: str) -> str:
        """Validate repository name against whitelist pattern."""
        # Only allow alphanumeric, dash, underscore
        pattern = r'^[a-zA-Z0-9_-]+$'

        if not re.match(pattern, v):
            raise ValueError(
                f"Repository name invalid. Must match pattern: {pattern}\n"
                f"Got: {v}"
            )

        return v

    @field_validator('deadline')
    @classmethod
    def validate_deadline(cls, v: str | None) -> str | None:
        """Validate deadline is future date in ISO 8601 format."""
        if v:
            try:
                from datetime import datetime, timezone
                deadline = datetime.fromisoformat(v)

                if deadline.tzinfo is None:
                    deadline = deadline.replace(tzinfo=timezone.utc)

                if deadline < datetime.now(timezone.utc):
                    raise ValueError('Deadline must be in the future')

            except ValueError as e:
                raise ValueError(f'Invalid date format. Use ISO 8601: {e}')

        return v
```

**Note**: Uses Pydantic v2 `@field_validator` instead of deprecated v1 `@validator`

### 3. Task-Specific Audit Logging (P0-3)

**Problem**: Audit logging not specific to task operations

**Solution**: Extend AuditLogger with task-specific events and sensitive field redaction

```python
class TaskAuditLogger(AuditLogger):
    """
    Task-specific audit logging with redaction.

    Events logged:
    - task_created
    - task_updated
    - task_deleted
    - task_assigned
    - task_started
    - task_completed
    - task_cancelled
    - task_blocked
    - task_unblocked
    """

    SENSITIVE_FIELDS = {
        'description',  # May contain sensitive information
        'metadata',     # May contain API keys, etc.
    }

    async def log_task_created(
        self,
        task_id: int,
        user_id: str,
        task_data: dict[str, Any],
    ) -> None:
        """Log task creation event."""
        await self.log(
            event_type="task_created",
            user_id=user_id,
            resource_type="task",
            resource_id=str(task_id),
            details=self._redact_sensitive_fields(task_data),
            timestamp=datetime.now(timezone.utc),
        )

    async def log_task_completed(
        self,
        task_id: int,
        user_id: str,
        quality_gate_result: dict[str, Any],
    ) -> None:
        """Log task completion event."""
        await self.log(
            event_type="task_completed",
            user_id=user_id,
            resource_type="task",
            resource_id=str(task_id),
            details={
                "quality_gate_passed": quality_gate_result.get("passed", False),
                "checks_run": len(quality_gate_result.get("checks", [])),
            },
            timestamp=datetime.now(timezone.utc),
        )

    def _redact_sensitive_fields(self, data: dict[str, Any]) -> dict[str, Any]:
        """Redact sensitive fields from audit log."""
        redacted = data.copy()

        for field in self.SENSITIVE_FIELDS:
            if field in redacted and redacted[field] is not None:
                # Redact value but keep length
                value = str(redacted[field])
                redacted[field] = f"[REDACTED ({len(value)} characters)]"

        return redacted
```

### 4. FTS Query Sanitization (P0-4)

**Problem**: Full-text search queries not sanitized

**Solution**: Add FTSSearchQuery Pydantic model with sanitization

```python
class FTSSearchQuery(BaseModel):
    """Full-text search query with sanitization."""

    query: str = Field(..., min_length=1, max_length=500)

    @field_validator('query')
    @classmethod
    def sanitize_query(cls, v: str) -> str:
        """Sanitize FTS query to prevent SQL injection."""
        # Remove null bytes
        v = v.replace('\x00', '')

        # Limit length
        if len(v) > 500:
            raise ValueError('Query too long (max 500 characters)')

        # Remove dangerous SQL characters (basic sanitization)
        # Note: PostgreSQL to_tsquery() will handle full escaping
        # This is just basic defense in depth
        dangerous_chars = [';', '--', '/*', '*/']
        for char in dangerous_chars:
            if char in v:
                raise ValueError(f"Query contains dangerous character: {char}")

        return v.strip()
```

### 5. Security Test Suite (P0-5)

**Problem**: No comprehensive security test suite

**Solution**: Create security test suite with SQL injection, path traversal, XSS, and auth bypass tests

```python
# tests/security/test_sql_injection.py
import pytest
from mahavishnu.core.models import TaskCreateRequest, FTSSearchQuery

class TestSQLInjection:
    """SQL injection prevention tests."""

    async def test_sql_injection_in_title(self, client):
        """Test SQL injection in task title."""
        malicious_inputs = [
            "'; DROP TABLE tasks; --",
            "' OR '1'='1",
            "1' UNION SELECT * FROM users--",
            "'; EXEC xp_cmdshell('format c:'); --",
        ]

        for payload in malicious_inputs:
            # Should raise ValueError (validation fails)
            with pytest.raises(ValueError):
                TaskCreateRequest(
                    title=payload,
                    repository="test-repo",
                )

    async def test_sql_injection_in_search(self, client):
        """Test SQL injection in search query."""
        malicious_queries = [
            "'; DROP TABLE tasks; --",
            "' OR '1'='1",
            "1' UNION SELECT * FROM users--",
        ]

        for query in malicious_queries:
            # Should raise ValueError (validation fails)
            with pytest.raises(ValueError):
                FTSSearchQuery(query=query)
```

**CI Integration**:

```yaml
# .github/workflows/security-tests.yml
name: Security Tests

on: [push, pull_request]

jobs:
  security-tests:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -e ".[dev]"

      - name: Run security tests
        run: pytest tests/security/ -v

      - name: Run Bandit security linter
        run: bandit -r mahavishnu/ -ll

      - name: Run Safety check
        run: safety check
```

---

## SRE & Reliability

### SRE Engineer Recommendations (6.5/10)

All 4 P0 SRE issues have been addressed:

### 1. Error Budget Enforcement Policy (P0-1)

**Problem**: No error budget enforcement policy defined

**Solution**: Document error budget calculation, burn rate alerting, and exhaustion procedures

```markdown
# Error Budget Policy

## SLI/SLO Summary

| SLI | SLO | Error Budget (Monthly) |
|-----|-----|------------------------|
| Task Creation Latency (p95) | < 100ms | 43.2 minutes |
| Task Availability | 99.9% | 43.2 minutes |
| Data Durability | 99.999% | 5 minutes/year |
| Workflow Success Rate | 95% | 5% failure rate |
| Webhook Availability | 99.5% | 216 minutes |
| Semantic Search Accuracy | 95% results returned | 5% failure rate |

## Error Budget Enforcement

### Alerting Thresholds

**Burn Rate Alerting**:
- Burn Rate 1x: Normal (error budget consumption within expected rate)
- Burn Rate 2x: Warning (consuming budget 2x faster than expected)
- Burn Rate 5x: Critical (consuming budget 5x faster than expected)

**Actions**:
- Burn Rate 2x for 5 minutes: Warning to on-call engineer
- Burn Rate 5x for 1 minute: Page on-call engineer immediately
- Burn Rate 10x for 30 seconds: Emergency, stop all deployments

### Error Budget Exhaustion

**When error budget exhausted**:
1. **Stop all non-emergency deployments** immediately
2. **Postmortem required** before resuming deployments
3. **Feature freeze** until error budget recovers
4. **Executive notification** if budget exhausted > 24 hours

### Error Budget Recovery

**Recovery Mechanisms**:
1. **Immediate Actions** (within 5 minutes):
   - Stop all deployments
   - Scale up infrastructure (if applicable)
   - Enable circuit breakers

2. **Short-term Actions** (within 1 hour):
   - Identify root cause
   - Implement hotfix
   - Verify fix in staging

3. **Long-term Actions** (within 24 hours):
   - Postmortem document
   - Prevent recurrence
   - Update runbooks
```

### 2. Disaster Recovery Testing Plan (P0-2)

**Problem**: No disaster recovery testing schedule

**Solution**: Schedule monthly DR tests with documented procedures

```markdown
# Disaster Recovery Testing Plan

## Monthly DR Test Schedule

**Test Window**: First Sunday of month, 2-4 AM UTC
**Advance Notice**: 1 week
**Duration**: 2 hours maximum

## Test Scenarios (Rotate Monthly)

### Month 1: Database Failure
1. Simulate PostgreSQL primary failure
2. Promote standby replica
3. Verify application connectivity
4. Verify data integrity

### Month 2: Application Server Failure
1. Terminate all application instances
2. Verify Kubernetes auto-recovery
3. Verify health checks trigger new pods
4. Verify traffic routing

### Month 3: Region Failure
1. Simulate complete region outage
2. Initiate DNS failover to secondary region
3. Verify application health in secondary region
4. Verify data replication lag < RPO

## DR Test Results Template

- Date: [Date]
- Scenario: [Scenario]
- RTO Achieved: [RTO]
- RPO Achieved: [RPO]
- Issues Found: [Issues]
- Actions Taken: [Actions]
- Next Steps: [Next Steps]
```

### 3. On-Call Procedures (P0-3)

**Problem**: On-call procedures undefined

**Solution**: Define on-call rotation, escalation paths, handoff procedures, and burden management

```markdown
# On-Call Handbook

## On-Call Rotation

### Structure

- **Primary On-Call**: First responder, handles all alerts
- **Shadow On-Call**: Learns from primary, backs up primary
- **Rotation**: Weekly rotation every Monday 9 AM UTC

### Responsibilities

**Primary On-Call**:
- Respond to all alerts within 15 minutes
- Investigate and resolve incidents
- Escalate if needed
- Document incidents

**Shadow On-Call**:
- Shadow primary during incidents
- Learn troubleshooting procedures
- Cover for primary during PTO/sick time

## Escalation Paths

### T0: Primary On-Call
- **Response Time**: 15 minutes
- **Responsibilities**: Initial investigation, resolution

### T1: Secondary On-Call (Previous week's primary)
- **Response Time**: 30 minutes
- **Responsibilities**: Assist primary, handle complex issues

### T2: Engineering Lead
- **Response Time**: 1 hour
- **Responsibilities**: Coordinate response, make decisions

### T3: CTO
- **Response Time**: 2 hours
- **Responsibilities**: Executive decisions, major incidents

## On-Call Burden Management

- **Max On-Call Weeks**: 1 week on, 3 weeks off
- **No On-Call During PTO**: Automatic reassignment
- **Shadow Rotation**: Required before becoming primary
- **Post-Incident Debrief**: Support after major incidents
```

### 4. Database Migration Rollback Triggers (P0-4)

**Problem**: Database migration rollback triggers incomplete

**Solution**: Document automated rollback conditions and procedures

**See ADR-003 for complete rollback trigger documentation**.

---

## User Experience

### UX Researcher Recommendations (7.5/10)

All 4 P0 UX issues have been addressed:

### 1. Skip Option for Onboarding (P0-1)

**Problem**: Forced onboarding for all users (including experienced users)

**Solution**: Add skip option at start of onboarding

```python
welcome_screen = """
Welcome to Mahavishnu Task Orchestration!

[New User] Press Enter for interactive tutorial (3 min)
[Experienced User] Type 'skip' to go to dashboard

> _"""
```

### 2. Accessibility Testing Moved to Phase 1 (P0-2)

**Problem**: Accessibility testing scheduled for Phase 5 (too late)

**Solution**: Move accessibility testing to Phase 1 Week 1

**Phase 1 Week 1 Accessibility Tasks**:
- [ ] WCAG 2.1 Level AA compliance testing (pa11y)
- [ ] Keyboard navigation testing
- [ ] Screen reader testing (NVDA, VoiceOver)
- [ ] Color contrast verification (4.5:1 minimum)

### 3. Terminal CLI Discoverability (P0-3)

**Problem**: Users can't find features without command palette

**Solution**: Add comprehensive --help output with command reference

```bash
$ mhv --help

Mahavishnu Task Orchestration v1.0

Usage:
  mhv [command] [options]

Commands (Task Management):
  create-task    Create a new task from natural language
  list-tasks     List all tasks with filters
  search-tasks   Semantic search across tasks
  start-task     Start working on a task
  complete-task  Mark task as complete

Commands (Worktrees):
  create-worktree    Create git worktree for task
  list-worktrees     Show all worktrees
  remove-worktree    Remove worktree

Commands (Quality):
  run-quality-gates Run quality checks before completion
  show-quality-report Display QC results

UI Modes:
  mhv --tui      Launch Terminal UI (split pane, keyboard nav)
  mhv --web      Launch Web UI (http://localhost:3000)
  mhv --help     Show this help message

Quick Reference:
  Ctrl+K         Command palette (fuzzy search)
  mhv tc         Shorthand for mhv task create
  mhv ts         Shorthand for mhv task search

Documentation: https://docs.mahavishnu.org
```

### 4. Phase 1 Timeline Extended (P0-4)

**Problem**: UX work squeezed into 1 week (Week 5)

**Solution**: Extend Phase 1 to 6 weeks, spread UX work across weeks 4-6

**Revised Phase 1 Timeline**:
- Week 1: NLP Parser + Accessibility Testing (NEW)
- Week 2: Task Storage PostgreSQL
- Week 3: Task CRUD Operations + Error Messages (NEW)
- Week 4: Semantic Search + Command Palette (UX work starts)
- Week 5: Onboarding Flow + User Testing (UX work continues)
- Week 6: UX Polish + Documentation (NEW)

---

## Storage Strategy

### PostgreSQL Schema (Simplified)

```sql
-- Users table (v3.1 addition - fixes P0 foreign key issue)
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    display_name VARCHAR(200),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    last_login_at TIMESTAMPTZ,
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    metadata JSONB DEFAULT '{}',
);
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);

-- Tasks table (core data + embeddings)
CREATE TABLE tasks (
    id BIGSERIAL PRIMARY KEY,
    title VARCHAR(200) NOT NULL,
    description TEXT,
    repository VARCHAR(100) NOT NULL,
    status VARCHAR(50) NOT NULL DEFAULT 'pending',
    priority VARCHAR(20) NOT NULL DEFAULT 'medium',
    created_by UUID NOT NULL REFERENCES users(id) ON DELETE RESTRICT,
    assigned_to UUID REFERENCES users(id) ON DELETE SET NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    completed_at TIMESTAMPTZ,
    deadline TIMESTAMPTZ,
    worktree_path TEXT,
    embedding VECTOR(1536),  -- OpenAI embeddings (pgvector)
    metadata JSONB DEFAULT '{}',
);

-- Indexes for performance
CREATE INDEX idx_tasks_repository ON tasks(repository);
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_priority ON tasks(priority);
CREATE INDEX idx_tasks_embedding ON tasks USING ivfflat(embedding vector_cosine_ops);

-- Composite indexes for common queries (v3.1 addition)
CREATE INDEX idx_tasks_status_priority ON tasks(status, priority);
CREATE INDEX idx_tasks_repository_status ON tasks(repository, status);
CREATE INDEX idx_tasks_assigned_status ON tasks(assigned_to, status) WHERE assigned_to IS NOT NULL;

-- Full-text search index
CREATE INDEX idx_tasks_fts ON tasks USING gin(to_tsvector('english', title || ' ' || COALESCE(description, '')));

-- Event sourcing log (append-only)
CREATE TABLE task_events (
    id BIGSERIAL PRIMARY KEY,
    task_id BIGINT NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,
    event_type VARCHAR(100) NOT NULL,
    event_data JSONB NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    version INT NOT NULL,
);
CREATE INDEX idx_task_events_task_id ON task_events(task_id);
CREATE INDEX idx_task_events_created_at ON task_events(created_at);

-- Audit log
CREATE TABLE audit_logs (
    id BIGSERIAL PRIMARY KEY,
    event_type VARCHAR(100) NOT NULL,
    user_id UUID NOT NULL,
    resource_type VARCHAR(50) NOT NULL,
    resource_id VARCHAR(100) NOT NULL,
    details JSONB NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
);
CREATE INDEX idx_audit_logs_user_id ON audit_logs(user_id);
CREATE INDEX idx_audit_logs_resource ON audit_logs(resource_type, resource_id);
CREATE INDEX idx_audit_logs_created_at ON audit_logs(created_at);

-- Saga log (for distributed transactions)
CREATE TABLE saga_log (
    id BIGSERIAL PRIMARY KEY,
    saga_id UUID NOT NULL UNIQUE,
    saga_type VARCHAR(100) NOT NULL,
    status VARCHAR(50) NOT NULL DEFAULT 'pending',
    current_step_index INT NOT NULL DEFAULT 0,
    completed_steps INT[] DEFAULT '{}',
    state JSONB NOT NULL DEFAULT '{}',
    error_message TEXT,
    retry_count INT DEFAULT 0,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
);
CREATE INDEX idx_saga_log_saga_id ON saga_log(saga_id);
CREATE INDEX idx_saga_log_status ON saga_log(status);
CREATE INDEX idx_saga_log_created_at ON saga_log(created_at);

-- Processed webhooks (replay attack prevention)
CREATE TABLE processed_webhooks (
    id BIGSERIAL PRIMARY KEY,
    webhook_id VARCHAR(200) NOT NULL UNIQUE,
    processed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
);
CREATE INDEX idx_processed_webhooks_webhook_id ON processed_webhooks(webhook_id);
```

---

## Implementation Phases

### Phase 0: Critical Security & SRE Fundamentals (6-8 weeks)

**BLOCKER - Must complete before Phase 1**

**Status**: Extended from 3-4 weeks based on SRE feedback

**Week 1-2: Security Fundamentals (Part 1)**
- [ ] Day 1-2: Webhook authentication with replay protection
- [ ] Day 3-4: Input sanitization framework (Pydantic v2 models)
- [ ] Day 5-7: Task-specific audit logging with redaction

**Week 3-4: Security Fundamentals (Part 2)**
- [ ] Day 8-10: Security test suite (SQL injection, XSS, auth bypass)
- [ ] Day 11-12: Security review and pen testing
- [ ] Day 13-14: Buffer and documentation

**Week 5-6: SRE Fundamentals (Part 1)**
- [ ] Day 15-17: SLI/SLO refinement and error budget policy
- [ ] Day 18-22: Monitoring and alerting (3 Grafana dashboards)
- [ ] Day 23-25: Deployment runbooks

**Week 7-8: SRE Fundamentals (Part 2)**
- [ ] Day 26-28: Disaster recovery procedures
- [ ] Day 29-31: On-call procedures
- [ ] Day 32-35: Validation and hardening (load testing, DR test)

**Deliverables**:
- All P0 security fixes implemented and tested
- SLI/SLOs defined and documented
- Monitoring dashboards deployed (3 dashboards)
- Alerting rules configured and tested
- Deployment runbooks created
- Disaster recovery procedures documented
- First disaster recovery test completed successfully
- On-call procedures defined

### Phase 1: Core Task Management (6 weeks, extended from 4-5 weeks)

**Week 1: NLP Parser + Accessibility Testing**
- [ ] Implement intent extraction from natural language
- [ ] Add confidence score calculation
- [ ] Handle uncertainty when confidence < 0.8
- [ ] **Accessibility testing (moved from Phase 5)**
  - WCAG 2.1 Level AA compliance (pa11y)
  - Keyboard navigation testing
  - Screen reader testing (NVDA, VoiceOver)
  - Color contrast verification

**Week 2: Task Storage (PostgreSQL)**
- [ ] Migrate from SQLite to PostgreSQL
- [ ] Implement event sourcing for task history
- [ ] Create database migration scripts
- [ ] Add connection pooling (asyncpg)

**Week 3: Task CRUD Operations + Error Messages**
- [ ] Create, read, update, delete tasks
- [ ] Task validation using Pydantic v2
- [ ] **Error messages with recovery guidance**
- [ ] **Command shorthands (mhv tc, mhv ts, etc.)**

**Week 4: Semantic Search + Command Palette**
- [ ] Generate embeddings for tasks
- [ ] Implement vector search with pgvector
- [ ] Add HNSW indexing for performance
- [ ] **Implement Ctrl+K fuzzy search command palette**
- [ ] **Add command categories**
- [ ] **Test command palette with 3-5 users**

**Week 5: Onboarding Flow + User Testing**
- [ ] **Implement interactive tutorial**
- [ ] **Add skip option for experienced users**
- [ ] **Configuration validation (repos.yaml)**
- [ ] **Error handling in onboarding**
- [ ] **User testing with 5-10 users**
- [ ] **Iterate based on feedback**

**Week 6: UX Polish + Documentation**
- [ ] **Fix issues from user testing**
- [ ] **Write quick start guide**
- [ ] **Record demo screencast**
- [ ] **Final accessibility testing**
- [ ] **Comprehensive --help command**

**Deliverables**:
- Working NLP parser with confidence scoring
- PostgreSQL database with task tables
- Semantic search with vector embeddings
- Command palette with fuzzy search
- Interactive onboarding flow with skip option
- Accessibility compliance (WCAG 2.1 Level AA)
- User testing completed with 5-10 participants

### Phase 2: Pattern Detection & Prediction (3 weeks)

**Week 1: Pattern Detection Engine**
- [ ] Implement pattern detection in PostgreSQL (pgvector)
- [ ] Analyze historical task data
- [ ] Detect recurring blockers
- [ ] Calculate task duration patterns

**Week 2: Predictive Insights**
- [ ] Predict potential blockers
- [ ] Estimate task duration
- [ ] Recommend optimal task ordering
- [ ] Display predictions in TUI

**Week 3: Dependency Management**
- [ ] Implement dependency graph
- [ ] Detect circular dependencies
- [ ] Visualize dependency chains
- [ ] Block/unblock tasks based on dependencies

**Deliverables**:
- Pattern detection engine
- Predictive blocker detection
- Task duration estimation
- Dependency management system

### Phase 3: Cross-Repository Coordination (3 weeks)

**Week 1: Multi-Repository Task Views**
- [ ] Aggregate tasks across repositories
- [ ] Filter by repository, tag, status
- [ ] Cross-repo task search
- [ ] Repository-specific dashboards

**Week 2: Cross-Repository Dependencies**
- [ ] Link tasks across repositories
- [ ] Track cross-repo blocking
- [ ] Coordinate task completion
- [ ] Multi-repo workflow orchestration

**Week 3: External Integrations**
- [ ] GitHub/GitLab webhook handlers
- [ ] One-way sync with approval workflow
- [ ] Import external issues
- [ ] Bi-directional sync opt-in (optional)

**Deliverables**:
- Multi-repository task views
- Cross-repository dependency tracking
- GitHub/GitLab integration
- One-way sync with approval workflow

### Phase 4: Quality Gate Integration (2 weeks)

**Week 1: Crackerjack Integration**
- [ ] Integrate Crackerjack MCP client
- [ ] Define quality gate rules
- [ ] Pre-completion validation
- [ ] Quality gate results display

**Week 2: Worktree Integration**
- [ ] Automatic worktree creation on task start
- [ ] Worktree lifecycle management
- [ ] Worktree-aware task completion
- [ ] Cleanup completed worktrees

**Deliverables**:
- Quality gate enforcement
- Automatic worktree creation
- Worktree lifecycle management

### Phase 5: User Interfaces (4-5 weeks)

**Week 1-2: CLI Enhancements**
- [ ] Command palette (Ctrl+K) - **Already done in Phase 1**
- [ ] Command shorthands - **Already done in Phase 1**
- [ ] Rich output formatting
- [ ] Progress indicators

**Week 3-4: Modern TUI**
- [ ] Textual-based TUI
- [ ] Split pane layout
- [ ] Keyboard navigation
- [ ] Contextual help
- [ ] Theme support

**Week 5: Accessibility Compliance - **Already done in Phase 1**
- [ ] WCAG 2.1 Level AA compliance
- [ ] Keyboard navigation
- [ ] Screen reader support
- [ ] Color contrast improvements
- [ ] Accessibility testing (pa11y)

**Deliverables**:
- Enhanced CLI with command palette
- Modern TUI with rich features
- Full accessibility compliance

### Phase 6: Native GUI (3-4 weeks)

**Week 1-2: SwiftUI macOS App**
- [ ] Create SwiftUI project (following mdinject architecture)
- [ ] Implement Unix Domain Socket IPC client (JSON-RPC 2.0)
- [ ] Build task list view with filtering
- [ ] Build task detail view
- [ ] Implement task creation/editing forms

**Week 3-4: Native Features & Real-Time**
- [ ] WebSocket integration for real-time updates
- [ ] macOS menu bar integration
- [ ] System notifications
- [ ] Keyboard shortcuts (Cmd+K command palette)
- [ ] Drag-and-drop task management
- [ ] Offline cache with sync

**Deliverables**:
- Native SwiftUI macOS application
- IPC client (JSON-RPC 2.0 over Unix socket)
- Real-time updates via WebSocket
- macOS system integration

**Future Enhancement**:
- Web PWA using FastBlocks/SplashStand (post-Phase 8)
- iOS/iPadOS app (shared SwiftUI codebase)

### Phase 7: Performance & Scalability (2-3 weeks)

**Week 1: Caching Layer**
- [ ] Redis integration (**Only if proven necessary - see ADR-001**)
- [ ] Cache frequent queries
- [ ] Cache invalidation strategy
- [ ] Cache hit rate monitoring

**Week 2: Query Optimization**
- [ ] EXPLAIN ANALYZE for slow queries
- [ ] Add database indexes
- [ ] Optimize N+1 queries
- [ ] Connection pooling optimization

**Week 3: Load Testing**
- [ ] k6 load testing scripts
- [ ] Performance benchmarks
- [ ] Scalability testing
- [ ] Performance tuning

**Deliverables**:
- Redis caching layer (**if monitoring proves necessity**)
- Optimized database queries
- Load testing results
- Performance benchmarks

### Phase 8: Deployment & Documentation (2-3 weeks)

**Week 1: Production Deployment**
- [ ] Blue-green deployment setup
- [ ] Kubernetes manifests
- [ ] Database migration scripts (see ADR-003)
- [ ] Monitoring and alerting setup

**Week 2-3: Documentation**
- [ ] User documentation
- [ ] API documentation
- [ ] Deployment guides
- [ ] Runbooks and troubleshooting

**Deliverables**:
- Production deployment
- Comprehensive documentation
- Deployment runbooks
- Monitoring dashboards

**Total Timeline: 26-32 weeks (6.5-8 months)**

---

## ADRs (Architecture Decision Records)

Three critical ADRs have been created to document architectural decisions:

### ADR-006: Simplify Storage Architecture

**Decision**: Simplify from 4-system to 2-system storage (PostgreSQL + optional Redis)

**Key Points**:
- 60% reduction in operational complexity
- Eliminates 2 critical failure modes
- Single source of truth (PostgreSQL)
- Redis deferred to Phase 7 (add only if proven necessary)

**File**: `/docs/adr/006-simplify-storage-architecture.md`

### ADR-007: Saga Coordinator Pattern

**Decision**: Implement persistent SagaCoordinator with crash recovery

**Key Points**:
- Persistent saga log in PostgreSQL
- Crash recovery on restart
- Exponential backoff retry
- Circuit breaker for failing steps
- Idempotent step execution

**File**: `/docs/adr/007-saga-coordinator-pattern.md`

### ADR-008: Zero-Downtime Migration

**Decision**: Zero-downtime SQLite â†’ PostgreSQL migration using dual-write strategy

**Key Points**:
- 4 phases: Dual-Write â†’ Dual-Read â†’ Cutover â†’ Cleanup
- Automated rollback triggers (data validation, performance regression, error rate)
- Comprehensive data validation (row count, hash comparison)
- 4 weeks migration timeline

**File**: `/docs/adr/008-zero-downtime-migration.md`

---

## Appendices

### Appendix A: Phase 0 Action Plan

**File**: `/docs/PHASE_0_ACTION_PLAN.md`

Complete step-by-step action plan for Phase 0 (6-8 weeks):

- Week 1-2: Security Fundamentals (Part 1)
- Week 3-4: Security Fundamentals (Part 2)
- Week 5-6: SRE Fundamentals (Part 1)
- Week 7-8: SRE Fundamentals (Part 2)

### Appendix B: 5-Agent Review Council Summary

**Overall Council Verdict**: APPROVED WITH CONDITIONS âš ï¸
**Average Score**: 7.04/10

| Agent | Score | Critical Issues |
|-------|-------|-----------------|
| Security Auditor | 7.5/10 | 5 P0 security fixes (4.5 days) |
| Architecture Reviewer | 4.2/5.0 | Simplify 4-system â†’ 2-system storage |
| UX Researcher | 7.5/10 | Extend Phase 1 to 6 weeks for UX |
| SRE Engineer | 6.5/10 | Extend Phase 0 to 6-8 weeks, add on-call |
| Python Pro | 8.5/10 | Fix Pydantic v2, async context managers |

### Appendix C: Success Metrics

**Technical Metrics**:
- Task creation latency p95 < 100ms âœ…
- Task availability 99.9% monthly âœ…
- Data durability 99.999% annual âœ…
- Workflow success rate 95% âœ…
- Webhook availability 99.5% âœ…
- Semantic search accuracy 95% results returned, 50% CTR âœ…

**User Adoption Metrics**:
- 50+ active users within 3 months
- 1000+ tasks created within 6 months
- 70%+ user retention (monthly active)

**Quality Metrics**:
- 90%+ test coverage
- Zero critical security vulnerabilities
- All type hints complete (mypy strict mode)
- Zero high-priority technical debt
- WCAG 2.1 Level AA compliant âœ…

### Appendix D: Risks & Mitigations

**Risk 1: NLP Parser Accuracy**
- **Probability**: Medium | **Impact**: High
- **Mitigation**: Confidence score threshold (0.8), user confirmation

**Risk 2: PostgreSQL Migration Complexity**
- **Probability**: Medium | **Impact**: Critical
- **Mitigation**: Dual-write migration with rollback triggers (ADR-003)

**Risk 3: Semantic Search Performance**
- **Probability**: Low | **Impact**: Medium
- **Mitigation**: HNSW indexing (O(log n)), Redis caching in Phase 7

**Risk 4: Cross-Repository Complexity**
- **Probability**: Medium | **Impact**: High
- **Mitigation**: Limit initial scope to 3-5 repositories, visualize dependencies

**Risk 5: Quality Gate Failures**
- **Probability**: Medium | **Impact**: Medium
- **Mitigation**: Configurable quality gates, manual override with justification

**Risk 6: User Adoption**
- **Probability**: Medium | **Impact**: High
- **Mitigation**: Focus on unique differentiators (semantic search, NLP), smooth onboarding, user testing

**Risk 7: AI Model Dependency** (v3.1 addition)
- **Probability**: Medium | **Impact**: High
- **Mitigation**: Support local embedding models (Ollama/fastembed) as fallback, hybrid retrieval

**Risk 8: Staff Turnover** (v3.1 addition)
- **Probability**: Low | **Impact**: Critical
- **Mitigation**: Comprehensive documentation, pair programming, knowledge sharing sessions

**Risk 9: Scope Creep** (v3.1 addition)
- **Probability**: High | **Impact**: High
- **Mitigation**: Strict change control board, MVP-first mentality, phase-gate criteria

**Risk 10: Webhook Rate Limiting** (v3.1 addition)
- **Probability**: Medium | **Impact**: Medium
- **Mitigation**: Implement batch processing, exponential backoff, queue-based processing

**Risk 11: WebSocket Scalability** (v3.1 addition)
- **Probability**: Low | **Impact**: Medium
- **Mitigation**: Load testing in Phase 7, consider Server-Sent Events fallback

**Risk 12: PostgreSQL Connection Pool Exhaustion** (v3.1 addition)
- **Probability**: Medium | **Impact**: High
- **Mitigation**: Monitor pool metrics, implement proper limits from Phase 0, async context managers

---

## Next Steps

1. âœ… **5-agent review completed** (2026-02-18)
2. âœ… **ADRs created** (ADR-001, ADR-002, ADR-003)
3. âœ… **Phase 0 Action Plan created**
4. âœ… **Master Plan v3.0 completed**
5. âœ… **4-agent Opus review completed** (2026-02-18)
6. âœ… **Master Plan v3.1 updated** with 4-agent feedback
7. âœ… **Phase 0 Action Plan updated** with missing items
8. **ðŸ”„ Begin Phase 0** (Critical Security & SRE Fundamentals)

**Estimated Timeline to Production**: 26-32 weeks (6.5-8 months)

---

**END OF MASTER PLAN v3.0**
