# Mahavishnu Unified Implementation Plan
**Version:** 1.1
**Date:** 2025-02-03
**Status:** ğŸ”¶ CONDITIONAL GO - P0 Blockers Must Be Addressed First
**Overall Timeline:** 22 weeks (5.5 months) realistic

---

## âš ï¸ TRIFECTA REVIEW FINDINGS

**Final Review Date:** 2025-02-03
**Overall Readiness: 6.3/10** ğŸ”´ **NOT PRODUCTION-READY**

Three specialized agents (Architect + Security + SRE) conducted comprehensive reviews. Key findings:

| Category | Score | Status | Decision |
|----------|-------|--------|----------|
| **Architecture** | 7.5/10 | ğŸŸ¡ Conditional GO | Fix EventBus + blocking operations |
| **Security** | 6.0/10 | ğŸ”´ Conditional GO | Fix 9 P0 vulnerabilities first |
| **Operations** | 5.5/10 | ğŸ”´ NO-GO | Define SLOs, add HA, fix blocking |

**Critical Blockers (P0):**
1. EventBus vs MessageBus confusion (2-3 days)
2. Unencrypted SQLite storage - CVSS 8.1 (5 days)
3. No authorization on code tools - CVSS 7.5 (3 days)
4. Full re-index blocking event loop (2 days)
5. No SLOs defined (3 days)
6. SSH credential exposure in logs - CVSS 8.5 (3 days)
7. MQTT device authentication missing - CVSS 7.8 (5 days)
8. No auto-restart mechanism (1 day)
9. Secrets in code graphs - CVSS 7.0 (5 days)

**Remediation Timeline:** 6 weeks for P0 fixes before implementation can begin.

**Full Review:** See `TRIFECTA_REVIEW_FINAL.md` for complete analysis.

---

## Executive Summary

This unified plan combines three major architectural enhancements into a coordinated implementation:

1. **Code Indexing Architecture** - Git-polling service with SQLite caching and event-driven integration
2. **Session-Buddy Memory Strategy** - Hybrid local + cloud storage for cross-worker learning
3. **Worker Expansion** - Six new workers (SSH, MQTT, Terminal, Docker, Database, Backup)

**Architecture Score (Post-Review): 7.5/10** (down from 8.5/10 due to critical gaps identified)

### Key Principles

- **Event-Driven Integration**: Message bus for loose coupling (ADR 003 compliant)
- **Error Resilience**: Circuit breakers, retry logic, DLQ for all services
- **Multi-Agent Quality**: Specialized agent reviews at each phase
- **Scalability First**: Git polling (not file watching), hybrid storage, connection pooling

---

## Table of Contents

1. [Part 1: Code Indexing Architecture](#part-1-code-indexing-architecture)
2. [Part 2: Session-Buddy Memory Strategy](#part-2-session-buddy-memory-strategy)
3. [Part 3: Worker Expansion](#part-3-worker-expansion)
4. [Part 4: Multi-Agent Review Strategy](#part-4-multi-agent-review-strategy)
5. [Part 5: Implementation Timeline](#part-5-implementation-timeline)
6. [Part 6: Agent Reviews](#part-6-agent-reviews)
7. [Part 7: Configuration Management](#part-7-configuration-management)
8. [Part 8: Testing Strategy](#part-8-testing-strategy)

---

## Part 1: Code Indexing Architecture

### Overview

Background code indexing service using git polling (100Ã— more scalable than file watching) with SQLite caching for fast startup and event-driven integration to Session-Buddy and Akosha.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mahavishnu (Orchestrator)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  CodeIndexService (NEW)                              â”‚    â”‚
â”‚  â”‚  - Git polling every 30s (jittered intervals)        â”‚    â”‚
â”‚  â”‚  - Full re-index using CodeGraphAnalyzer            â”‚    â”‚
â”‚  â”‚  - SQLite caching (data/code_index_cache.db)        â”‚    â”‚
â”‚  â”‚  - ADR 003 error handling (retry, CB, DLQ)          â”‚    â”‚
â”‚  â”‚  - MCP tools for querying                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                   â”‚
â”‚                           â”‚ Publish Event                     â”‚
â”‚                           â–¼                                   â”‚
â”‚                     Message Bus                              â”‚
â”‚                           â”‚                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚            â–¼                             â–¼                   â”‚
â”‚  Session-Buddy (Memory)          Akosha (Patterns)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Design Decisions

| Decision | Rationale |
|----------|-----------|
| **Git polling over file watching** | macOS limit: ~10K file descriptors. 100 repos Ã— 50K files = FAILS. Git polling scales to 100+ repos |
| **Full re-index (not incremental)** | CodeGraphAnalyzer lacks incremental APIs. Would require 2-3 days to add. Full re-index is simpler and works now |
| **SQLite cache in Mahavishnu** | Fast startup (<100ms load), works offline, source of truth |
| **Event-driven (not push)** | Loose coupling via message bus. Session-Buddy down â†’ no impact on indexing |
| **Jittered polling intervals** | Prevent thundering herd. 100 repos checking simultaneously can overwhelm service |

### Implementation Phases

#### Phase 1: Background Indexing Service (2-3 days)

**File: `mahavishnu/core/code_index_service.py`**

```python
class CodeIndexService:
    """Git-polling code indexing service with full re-indexing."""

    def __init__(self, app: MahavishnuApp):
        self.app = app
        self.recovery = app.error_recovery_manager  # ADR 003
        self.dlq = app.dlq
        self._cache_path = Path("data/code_index_cache.db")
        self._poll_interval = 30  # seconds

    async def start_git_polling(self):
        """Poll git repos for commits (jittered intervals)."""
        while True:
            repos = self.app.repo_manager.get_all()
            for repo in repos:
                # Add jitter based on repo hash (Â±5 seconds)
                jitter = self._calculate_jitter(repo.path)
                await asyncio.sleep(jitter)

                if await self._has_new_commit(repo.path):
                    await self._trigger_indexing(repo.path)

            # Base interval before next cycle
            await asyncio.sleep(self._poll_interval)

    async def _trigger_indexing(self, repo_path: Path):
        """Index with resilience pattern (retry, CB, DLQ)."""
        try:
            stats = await self.recovery.execute_with_retry(
                self._full_index_repo,
                repo_path,
                recovery_key="CODE_INDEX",
                max_attempts=3
            )

            # Publish event (not direct push)
            await self.message_bus.publish(
                "code.graph.indexed",
                {"repo": str(repo_path), "stats": stats}
            )

        except PermanentFailure as e:
            await self.dlq.enqueue(
                task_id=f"index_{repo_path}",
                task={"type": "index", "path": str(repo_path)},
                repos=[str(repo_path)],
                error=str(e)
            )

    async def _full_index_repo(self, repo_path: Path) -> dict:
        """Full re-index using CodeGraphAnalyzer (not incremental)."""
        analyzer = CodeGraphAnalyzer(repo_path)
        stats = await analyzer.analyze_repository(str(repo_path))
        await self._save_to_cache(repo_path, analyzer.nodes, stats)
        return stats

    def _calculate_jitter(self, repo_path: Path) -> float:
        """Calculate jitter based on repo hash (deterministic)."""
        import hashlib
        hash_val = int(hashlib.md5(str(repo_path).encode()).hexdigest(), 16)
        return 5.0 * (hash_val % 100) / 100.0  # 0-5 seconds
```

**MCP Tools: `mahavishnu/mcp/tools/code_index_tools.py`**

- `list_indexed_repos()` - Show indexing status and timestamps
- `get_function_context(repo, function_name)` - Get context with dependencies
- `find_related_code(repo, function_name)` - Find callers/callees
- `trigger_reindex(repo)` - Manually trigger re-indexing

#### Phase 2: SQLite Persistence (1-2 days)

**Schema:**

```sql
CREATE TABLE code_graphs (
    repo_path TEXT PRIMARY KEY,
    commit_hash TEXT,
    indexed_at TIMESTAMP,
    nodes_count INTEGER,
    graph_data JSON  -- serialized CodeGraphAnalyzer.nodes
);

CREATE INDEX idx_repo_commits ON code_graphs(repo_path, commit_hash);
```

**File: `mahavishnu/storage/sqlite_cache.py`**

```python
class SQLiteCodeCache:
    """SQLite persistence for code graphs."""

    async def save_graph(self, repo_path: Path, commit_hash: str, graph_data: dict):
        """Save code graph to cache."""

    async def load_graph(self, repo_path: Path) -> dict | None:
        """Load code graph from cache."""

    async def list_repos(self) -> list[dict]:
        """List all indexed repos with metadata."""
```

#### Phase 3: Event-Driven Integration (2 days)

**Mahavishnu Publisher:**

```python
# In CodeIndexService._trigger_indexing()
await self.message_bus.publish("code.graph.indexed", {
    "repo": str(repo_path),
    "commit": commit_hash,
    "graph": code_graph,
    "stats": stats
})
```

**Session-Buddy Subscriber: `session_buddy/subscribers/code_graph_subscriber.py`**

```python
class CodeGraphSubscriber:
    def __init__(self, message_bus, reflection_db):
        self.message_bus = message_bus
        self.message_bus.subscribe("code.graph.indexed", self.on_graph_indexed)

    async def on_graph_indexed(self, event):
        """Store code graph in Reflection DB."""
        await self.reflection_db.store_code_graph(event.data)
```

### Performance Projections

- **Memory**: 800MB-1.5GB for 10 repos
- **Disk**: 100MB-500MB per repo (cached graphs)
- **Polling overhead**: 20 polls/min subprocess spawn (acceptable)
- **Full re-index**: ~50s for 1K file repo (blocking, needs executor)

---

## Part 2: Session-Buddy Memory Strategy

### Overview

Hybrid storage architecture combining local DuckDB cache for speed with cloud storage (S3/GCS/Azure) for cross-worker learning and global analytics.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Session-Buddy (Worker 1)         â”‚  Session-Buddy (Worker N)  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Local DuckDB Cache       â”‚    â”‚  â”‚ Local DuckDB Cache    â”‚ â”‚
â”‚  â”‚ (~/.claude/data/)       â”‚    â”‚  â”‚ (~/.claude/data/)     â”‚ â”‚
â”‚  â”‚ - Fast semantic search  â”‚    â”‚  â”‚ - Fast semantic searchâ”‚ â”‚
â”‚  â”‚ - Offline capable       â”‚    â”‚  â”‚ - Offline capable    â”‚ â”‚
â”‚  â”‚ - HNSW vector index     â”‚    â”‚  â”‚ - HNSW vector index  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚              â”‚                    â”‚              â”‚              â”‚
â”‚              â†“                   â†“              â†“              â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚         â”‚  Shared Cloud Storage                â”‚         â”‚
â”‚         â”‚  (S3 / GCS / Azure)                  â”‚         â”‚
â”‚         â”‚  - All workers push to same bucket   â”‚         â”‚
â”‚         â”‚  - Enables cross-instance learning   â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â†“
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  Akosha (Soothsayer)  â”‚
                            â”‚  - Pulls from shared   â”‚
                            â”‚  - Pattern detection  â”‚
                            â”‚  - Cross-user analyticsâ”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration Options

**Option A: S3 (Recommended - Simple)**
```yaml
# settings/session-buddy.yaml
storage:
  default_backend: "s3"
  s3:
    bucket_name: "session-buddy-${USER}"
    endpoint_url: "${S3_ENDPOINT:-}"  # Empty for AWS, set for MinIO
```

**Option B: GCS**
```yaml
storage:
  default_backend: "gcs"
  gcs:
    bucket_name: "session-buddy-${USER}"
    project: "your-project-id"
```

**Option C: Azure**
```yaml
storage:
  default_backend: "azure"
  azure:
    account_name: "youraccount"
    container: "session-buddy"
```

**Option D: Local Filesystem (Simplest, No cloud)**
```yaml
storage:
  default_backend: "file"
  file:
    local_path: "~/.claude/data/sessions"
```

### Benefits

| Benefit | Description |
|---------|-------------|
| **Speed** | Local DuckDB cache = instant semantic search (HNSW indexing) |
| **Continuity** | Cloud storage = access from any device |
| **Privacy** | Sensitive data stays local, only embeddings go to cloud |
| **Resilient** | Works offline, syncs when connected |
| **Analytics** | Akosha can analyze all your work over time |

### Cost Estimate

**Per month** (single user, moderate usage):
- **DuckDB local**: ~500MB-2GB (free)
- **S3 Standard**: ~10-50GB sessions + embeddings (~$0.23/GB)
  - 10GB: ~$2.30/month
  - 50GB: ~$11.50/month

**Total**: Under $15/month for comprehensive memory storage

### Implementation

**Phase 1: Enable Cloud Storage Backend**

1. Configure Session-Buddy to use S3/GCS/Azure in `settings/session-buddy.yaml`
2. Local cache (DuckDB) remains at `database_path: "~/.claude/data/reflection.duckdb"`

**Phase 2: Akosha Integration Pattern**

```python
# Akosha pulls from shared storage (not polling)
class SessionBuddyMemoryIngester:
    """Ingest Session-Buddy memory from shared storage."""

    async def sync_from_s3(self):
        """Pull new sessions from S3 bucket."""
        new_sessions = await self.s3_client.list_new_objects(
            bucket="session-buddy-${USER}",
            since_last_sync
        )

        for session_obj in new_sessions:
            session_data = await self.s3_client.get_object(session_obj)
            await self.ingest_session_memory(session_data)
```

---

## Part 3: Worker Expansion

### Overview

Six new workers to extend Mahavishnu's orchestration capabilities across SSH, IoT, containers, databases, and backups.

### Workers Summary

| Worker | Priority | Complexity | Timeline | Use Cases |
|--------|----------|------------|----------|-----------|
| **SSH/SFTP** | P1 | Medium | 3-4 days | Remote command execution, file transfers |
| **MQTT** | P2 | Low-Medium | 2-3 days | IoT device control, edge computing |
| **Interactive Terminal** | P1 | Medium | 2-3 days | Interactive Claude/Qwen sessions |
| **Docker/Cloud Run** | P1 | Medium | 3-4 days | Container orchestration, serverless deployment |
| **Database** | P2 | Low | 2 days | Query execution, schema migrations |
| **Backup** | P2 | Low-Medium | 2-3 days | Automated backups, restore operations |

### SSH Worker (Priority 1)

**Capabilities:**
- Non-interactive command execution
- Interactive PTY sessions (vim, nano, etc.)
- SFTP file transfers (upload, download, delete, list)
- Connection pooling (max 10 concurrent connections)

**Technology:**
- Library: **asyncssh** (async-native, actively maintained, 2024 releases)
- NOT paramiko (synchronous only, blocks event loop)
- NOT "native Python SSH" (does not exist - common misconception)

**Oneiric Adapter:**

```yaml
category: "ssh"
provider: "asyncssh"
factory: "oneiric.adapters.ssh.client:SSHClientAdapter"
capabilities:
  - execute_non_interactive
  - execute_interactive
  - sftp_upload
  - sftp_download
  - sftp_list
  - sftp_delete
settings_model: SSHClientSettings
```

**MCP Tools:**
- `ssh_execute(host, command, interactive=False)` - Execute command
- `ssh_upload(host, local_path, remote_path)` - Upload file via SFTP
- `ssh_download(host, remote_path, local_path)` - Download file via SFTP
- `ssh_list_sessions()` - List active SSH connections
- `ssh_close_session(session_id)` - Close SSH session

**Key Features:**
```python
# Non-interactive command
result = await ssh_worker.execute(
    host="example.com",
    command="ls -la",
    timeout=300
)

# Interactive session (PTY allocation)
await ssh_worker.start_interactive(
    host="example.com",
    term_type="xterm-256color"
)

# SFTP upload
await ssh_worker.upload(
    host="example.com",
    local_path="/tmp/file.txt",
    remote_path="/remote/file.txt"
)
```

### MQTT Worker (Priority 2)

**Capabilities:**
- Publish messages to topics
- Subscribe to topics with QoS levels
- Last Will and Testament (LWT)
- Retained messages
- Connection pooling for multiple brokers

**Technology:**
- Library: **gmqtt** (async-native MQTT 5.0 client)
- NOT paho-mqtt (synchronous only)

**Oneiric Adapter:**

```yaml
category: "mqtt"
provider: "gmqtt"
factory: "oneiric.adapters.mqtt.client:MQTTClientAdapter"
capabilities:
  - publish
  - subscribe
  - unsubscribe
  - last_will_testament
settings_model: MQTTClientSettings
```

**MCP Tools:**
- `mqtt_publish(broker, topic, payload, qos, retain)` - Publish message
- `mqtt_subscribe(broker, topic, qos, callback_url)` - Subscribe to topic
- `mqtt_unsubscribe(broker, topic)` - Unsubscribe from topic
- `mqtt_list_subscriptions(broker)` - List active subscriptions
- `mqtt_disconnect(broker)` - Disconnect from broker

**IoT Use Cases:**
- Control ESP32 devices at the edge
- Monitor sensor data (temperature, humidity)
- Trigger session-buddy restarts on edge devices
- Coordinate MCP server deployments across edge nodes

### Interactive Terminal Worker (Priority 1)

**Capabilities:**
- PTY allocation for interactive sessions
- Keystroke injection for Claude/Qwen CLI tools
- Stream-json parsing for real-time output
- Session management (start, stop, status)

**Technology:**
- PTY allocation via `asyncssh.create_process(term_type='xterm-256color')`
- Or `ptyprocess` library for local pseudo-terminals

**MCP Tools:**
- `terminal_start_interactive(session_id, command)` - Start interactive session
- `terminal_send_keystrokes(session_id, keystrokes)` - Send keystrokes
- `terminal_capture_output(session_id, lines)` - Capture output
- `terminal_stop(session_id)` - Stop session
- `terminal_list_sessions()` - List all sessions

**Key Features:**
```python
# Start interactive Claude session
session_id = await terminal_worker.start_interactive(
    command="claude --output-format stream-json --permission-mode acceptEdits"
)

# Send keystrokes
await terminal_worker.send_keystrokes(
    session_id=session_id,
    keystrokes="Write a Python function to reverse a string\n"
)

# Capture output
output = await terminal_worker.capture_output(
    session_id=session_id,
    lines=50
)
```

### Docker/Cloud Run Worker (Priority 1)

**Capabilities:**
- Build images with Cloud Native Buildpacks (preferred)
- Deploy containers to Cloud Run (serverless)
- Local container orchestration via OrbStack
- Container lifecycle management (start, stop, logs)

**Technology:**
- **Buildpacks** (preferred over Dockerfiles)
- **OrbStack** on macOS (2-5x faster than Docker Desktop)
- **Google Cloud Run** for serverless deployment

**Oneiric Adapter:**

```yaml
category: "container"
provider: "cloud-run"
factory: "oneiric.adapters.container.cloud_run:CloudRunAdapter"
capabilities:
  - build_with_buildpacks
  - deploy_cloud_run
  - list_containers
  - get_logs
  - stop_container
settings_model: CloudRunSettings
```

**MCP Tools:**
- `container_build(source_dir, builder_type)` - Build image (buildpacks/Dockerfile)
- `container_deploy(image, service_name, region)` - Deploy to Cloud Run
- `container_list(region)` - List containers
- `container_logs(service_name, region, tail)` - Get logs
- `container_stop(service_name, region)` - Stop container

**Deployment Flow:**
```python
# Build with buildpacks
image_url = await container_worker.build(
    source_dir="/path/to/app",
    builder_type="buildpacks"  # or "dockerfile"
)

# Deploy to Cloud Run
service_url = await container_worker.deploy(
    image_url=image_url,
    service_name="my-service",
    region="us-central1",
    memory="512Mi",
    cpu="1",
    max_instances=100
)
```

### Database Worker (Priority 2)

**Capabilities:**
- Execute SQL queries (PostgreSQL, MySQL, SQLite)
- Schema migrations
- Connection pooling
- Query result formatting

**Technology:**
- **asyncpg** for PostgreSQL (async-native)
- **aiomysql** for MySQL (async-native)
- **aiosqlite** for SQLite (async-native)

**Oneiric Adapter:**

```yaml
category: "database"
provider: "multi-dialect"
factory: "oneiric.adapters.database.client:DatabaseClientAdapter"
capabilities:
  - execute_query
  - execute_script
  - migrate_schema
  - backup_database
settings_model: DatabaseClientSettings
```

**MCP Tools:**
- `db_execute(conn_name, query)` - Execute query
- `db_execute_script(conn_name, script_path)` - Execute SQL script
- `db_migrate(conn_name, migration_direction)` - Run migration
- `db_backup(conn_name, backup_path)` - Backup database
- `db_list_connections()` - List configured connections

### Backup Worker (Priority 2)

**Capabilities:**
- Automated repository backups
- Database backups
- Scheduled backups with retention policies
- Restore operations

**Technology:**
- Git-based backups for repos
- Database dump for databases
- Cloud storage for off-site backups (S3, GCS, Azure)

**Oneiric Adapter:**

```yaml
category: "backup"
provider: "multi-destination"
factory: "oneiric.adapters.backup.manager:BackupManagerAdapter"
capabilities:
  - backup_repo
  - backup_database
  - schedule_backup
  - restore_backup
  - list_backups
settings_model: BackupManagerSettings
```

**MCP Tools:**
- `backup_repo(repo_path, destination)` - Backup repository
- `backup_database(conn_name, destination)` - Backup database
- `backup_schedule(repo_path, schedule, retention)` - Schedule backups
- `backup_restore(backup_id, destination)` - Restore from backup
- `backup_list(destination)` - List available backups

---

## Part 4: Multi-Agent Review Strategy

### Overview

Bake multi-agent reviews into the development workflow to ensure architecture soundness, security, and operational readiness at each phase.

### Review Triggers

| Phase | Review Type | Agents | Purpose |
|-------|-------------|--------|---------|
| **Design Complete** | Architecture Review | Architect-reviewer, Code-architect | Validate soundness, identify gaps |
| **Pre-Implementation** | Security Review | Security-auditor, Security-engineer | Identify vulnerabilities, threat model |
| **Implementation Ready** | Operations Review | SRE-engineer, Devops-engineer | Validate production readiness |
| **Code Complete** | Code Review | Code-reviewer, Test-coverage-reviewer | Quality, test coverage |
| **Pre-Deployment** | Trifecta Review | Architect + Security + SRE | Final GO/NO-GO decision |

### Review Process

#### Phase 1: Design Review (Before Implementation)

**Launch:**
```bash
# Use Task tool with multiple agents in parallel
Task(subagent_type="architect-reviewer", prompt="Review architecture for soundness")
Task(subagent_type="code-architect", prompt="Validate design patterns and abstractions")
Task(subagent_type="performance-engineer", prompt="Analyze performance bottlenecks")
```

**Deliverables:**
- Architecture score (1-10)
- Critical gaps identification
- Design flaw analysis
- Revised recommendations

#### Phase 2: Security Review (Before Coding)

**Launch:**
```bash
Task(subagent_type="security-auditor", prompt="Security and vulnerability assessment")
Task(subagent_type="security-engineer", prompt="DevSecOps and controls validation")
Task(subagent_type="penetration-tester", prompt="Threat modeling and attack vectors")
```

**Deliverables:**
- Security score (1-10)
- CVSS scores for vulnerabilities
- Remediation priority (P0/P1/P2)
- Compliance gaps (GDPR, SOC 2, ISO 27001)

#### Phase 3: Operations Review (Before Deployment)

**Launch:**
```bash
Task(subagent_type="sre-engineer", prompt="Reliability and resilience assessment")
Task(subagent_type="devops-engineer", prompt="Deployment and automation validation")
Task(subagent_type="performance-monitor", prompt="Performance and resource analysis")
```

**Deliverables:**
- Operations score (1-10)
- SLO definitions
- Monitoring requirements
- Disaster recovery procedures

#### Phase 4: Trifecta Review (Final GO/NO-GO)

**Launch:**
```bash
# 3 agents review simultaneously
Task(subagent_type="architect-reviewer", prompt="Final architecture validation")
Task(subagent_type="security-auditor", prompt="Final security assessment")
Task(subagent_type="sre-engineer", prompt="Final operations readiness")
```

**Deliverables:**
- Overall readiness score (1-10)
- GO/NO-GO decision
- Critical blockers list
- Estimated remediation time

### Review Documentation

All reviews must be documented in:

```
/Users/les/Projects/mahavishnu/docs/reviews/
â”œâ”€â”€ REVIEW_YYYYMMDD_architecture_code-index.md
â”œâ”€â”€ REVIEW_YYYYMMDD_security_ssh-worker.md
â”œâ”€â”€ REVIEW_YYYYMMDD_operations_mqtt-worker.md
â””â”€â”€ TRIFECTA_REVIEW_YYYYMMDD_unified-plan.md
```

### Review Checklist Template

```markdown
# Review: [Feature Name]

**Date:** YYYY-MM-DD
**Reviewer:** [Agent Name]
**Review Type:** [Architecture/Security/Operations]

## Score: X/10

## Strengths
- âœ… ...

## Critical Gaps
- âŒ **[ID] [Title]** - Description
  - **Fix Required:** ...
  - **Timeline:** X days

## Recommendations
1. **Priority 0 (Must Fix):** ...
2. **Priority 1 (Should Fix):** ...
3. **Priority 2 (Nice to Have):** ...

## Final Verdict
[GO / NO-GO] with conditions: ...

---
**Review Completed:** YYYY-MM-DD
**Next Review:** After remediation (estimated YYYY-MM-DD)
```

---

## Part 5: Implementation Timeline

### Overall Timeline: 5-7 weeks

### Week 1-2: Code Indexing Architecture

| Phase | Tasks | Days | Status |
|-------|-------|------|--------|
| **Phase 0** | Architecture & Security Fixes | 5 | Pending |
| **Phase 1** | Background Indexing Service | 3 | Pending |
| **Phase 2** | SQLite Persistence | 2 | Pending |
| **Phase 3** | Event-Driven Integration | 2 | Pending |
| **Phase 4** | MCP Tools & Testing | 4 | Pending |
| **Phase 5** | Hardening & Docs | 3 | Pending |

**Milestone:** Code graphs indexed for 10+ repos, events flowing to Session-Buddy

### Week 3: Session-Buddy Memory Strategy

| Phase | Tasks | Days | Status |
|-------|-------|------|--------|
| **Phase 1** | Enable Cloud Storage Backend | 1 | Pending |
| **Phase 2** | Akosha Integration Pattern | 2 | Pending |
| **Phase 3** | Testing & Validation | 2 | Pending |

**Milestone:** Hybrid storage active, cross-worker learning enabled

### Week 4-5: Worker Expansion (Priority 1 Workers)

| Worker | Tasks | Days | Status |
|--------|-------|------|--------|
| **SSH** | Implementation + Oneiric adapter | 3 | Pending |
| **Interactive Terminal** | PTY allocation + keystrokes | 2 | Pending |
| **Docker/Cloud Run** | Buildpacks + deployment | 3 | Pending |
| **Testing** | Integration tests for all P1 workers | 2 | Pending |

**Milestone:** P1 workers operational, end-to-end workflows tested

### Week 6: Worker Expansion (Priority 2 Workers)

| Worker | Tasks | Days | Status |
|--------|-------|------|--------|
| **MQTT** | Implementation + IoT scenarios | 2 | Pending |
| **Database** | Multi-dialect support | 2 | Pending |
| **Backup** | Automated backups + restore | 2 | Pending |
| **Testing** | Integration tests for all P2 workers | 1 | Pending |

**Milestone:** All 6 workers operational

### Week 7: Hardening & Documentation

| Phase | Tasks | Days | Status |
|-------|-------|------|--------|
| **Trifecta Review** | Final GO/NO-GO review | 1 | Pending |
| **Security Hardening** | Address P0/P1 issues | 2 | Pending |
| **Performance Tuning** | Optimize bottlenecks | 1 | Pending |
| **Documentation** | User guides, API docs | 2 | Pending |
| **Deployment** | Staging deployment + validation | 1 | Pending |

**Milestone:** Production-ready system deployed to staging

---

## Part 6: Agent Reviews

### Trifecta Review Summary (Code Indexing Architecture)

**Date:** 2025-02-03
**Agents:** Architect-reviewer, Security-auditor, SRE-engineer

**Overall Readiness: 6.5/10** ğŸ”´ **NOT PRODUCTION-READY**

| Category | Score | Status |
|----------|-------|--------|
| Architecture | 8.5/10 | ğŸŸ¡ Good with critical gaps |
| Security | 6.5/10 | ğŸ”´ High risk - critical vulnerabilities |
| Operations | 6.5/10 | ğŸ”´ Not production-ready |

**Critical Issues Identified:**

1. **EventBus vs MessageBus Confusion (CRITICAL)**
   - Current `MessageBus` is pool-scoped, not system-wide
   - Fix: Create separate `EventBus` for system-wide events with persistence

2. **Blocking Full Re-Index (HIGH)**
   - Full re-index blocks event loop for 50+ seconds
   - Fix: Use `run_in_executor` to avoid blocking

3. **Polling Thundering Herd (HIGH)**
   - 100 repos Ã— 30s polling = synchronized checking
   - Fix: Add jittered intervals (Â±5 seconds based on repo hash)

4. **Unencrypted Code Storage (CVSS 8.1) - CRITICAL**
   - Source code stored in plaintext SQLite
   - Fix: Use SQLCipher for encrypted SQLite

5. **No Authorization on Code Query Tools (CVSS 7.5) - CRITICAL**
   - Anyone can query any indexed repo
   - Fix: Add `@require_auth` + RBAC to all MCP tools

**Recommendation:** Address all P0 issues before implementation. Estimated remediation: 2-3 weeks.

### Individual Agent Reviews

#### Architect-Reviewer

**Focus:** Architecture soundness, scalability, design patterns

**Key Findings:**
- âœ… Git polling is the right choice (100Ã— more scalable than file watching)
- âœ… Event-driven architecture with loose coupling
- âœ… ADR 005 compliance (Session-Buddy as memory manager)
- âŒ EventBus vs MessageBus confusion needs resolution
- âŒ Blocking full re-index needs executor wrapper

**Score:** 8.5/10

#### Security-Auditor

**Focus:** Security vulnerabilities, threat modeling, compliance

**Key Findings:**
- âŒ Unencrypted code storage (CVSS 8.1) - CRITICAL
- âŒ No authorization on code query tools (CVSS 7.5) - CRITICAL
- âŒ Secrets in code graphs (CVSS 7.0) - HIGH
- âŒ Plaintext message bus (CVSS 6.5) - MEDIUM
- âŒ No audit logging (CVSS 5.5) - MEDIUM

**Compliance Gaps:**
- GDPR: No right to erasure, no data minimization
- SOC 2 / ISO 27001: No access logging, no encryption at rest

**Score:** 6.5/10

#### SRE-Engineer

**Focus:** Operational readiness, reliability, monitoring

**Key Findings:**
- âœ… ADR 003 error handling (retry, CB, DLQ)
- âœ… BackupManager exists
- âŒ No circuit breaker for git polling
- âŒ Message bus data loss on restart
- âŒ No cache validation on startup
- âŒ SLOs undefined (freshness, availability, performance)

**Single Points of Failure:**
1. Mahavishnu process (no HA, no auto-restart)
2. MessageBus in-memory queue (no persistence)
3. SQLite cache file (backup only, RPO 24h)
4. Git repo access (no circuit breaker)

**Score:** 6.5/10

#### Cloud-Architect (IoT/Edge)

**Focus:** MQTT, IoT edge computing, ESP32 integration

**Key Findings:**
- âœ… MQTT worker design is sound for IoT use cases
- âœ… QoS levels 0/1/2 support for different reliability needs
- âœ… Last Will and Testament for edge device failure detection
- âœ… Retained messages for edge device state synchronization
- âœ… Connection pooling for multi-broker scenarios

**Recommendations:**
- Add edge device health monitoring (heartbeat mechanism)
- Implement edge-specific security (device certificates, mutual TLS)
- Consider edge-specific message routing patterns

**Score:** 8.5/10 (IoT/edge specific)

#### DevOps-Engineer (Cloud Run/Docker)

**Focus:** Container orchestration, buildpacks, deployment

**Key Findings:**
- âœ… Buildpacks preference is correct (simpler than Dockerfiles)
- âœ… Cloud Run serverless deployment strategy
- âœ… OrbStack on macOS (2-5x faster than Docker Desktop)
- âœ… Container lifecycle management design
- âš ï¸ Missing container resource limits (memory, CPU)
- âš ï¸ No container health checks defined

**Recommendations:**
- Add resource limits to container deployment spec
- Implement health check endpoints (/health, /ready)
- Add container metrics (CPU, memory, restarts)
- Implement rollback strategy for failed deployments

**Score:** 8/10

---

## Part 7: Configuration Management

### Oneiric Integration

All new workers and services use Oneiric configuration patterns with layered loading:

1. Default values in Pydantic models
2. `settings/mahavishnu.yaml` (committed)
3. `settings/local.yaml` (gitignored, local dev)
4. Environment variables `MAHAVISHNU_{FIELD}`

### Configuration Files

#### `settings/mahavishnu.yaml`

```yaml
# Code Indexing
code_indexing:
  enabled: true
  poll_interval: 30  # seconds
  jitter_enabled: true
  jitter_range: 5.0  # seconds
  cache_path: "data/code_index_cache.db"
  max_parallel_index: 5  # concurrent repos

# Workers
workers:
  ssh:
    enabled: true
    max_connections: 10
    connection_timeout: 30
    default_term_type: "xterm-256color"

  mqtt:
    enabled: true
    default_qos: 1
    max_connections: 5
    keep_alive: 60

  terminal:
    enabled: true
    max_sessions: 10
    default_shell: "/bin/bash"

  container:
    enabled: true
    preferred_builder: "buildpacks"  # or "dockerfile"
    default_region: "us-central1"
    max_memory: "512Mi"
    max_cpu: "1"

  database:
    enabled: true
    connection_pool_size: 10
    query_timeout: 300

  backup:
    enabled: true
    default_retention_days: 30
    backup_schedule: "0 2 * * *"  # 2 AM daily
    default_destination: "s3://mahavishnu-backups"

# Pools
pools_enabled: true
default_pool_type: "mahavishnu"
pool_routing_strategy: "least_loaded"

# Memory Aggregation
memory_aggregation_enabled: true
memory_sync_interval: 60
session_buddy_pool_url: "http://localhost:8678/mcp"
akosha_url: "http://localhost:8682/mcp"
```

#### `settings/session-buddy.yaml`

```yaml
# Storage Backend
storage:
  default_backend: "s3"  # or "gcs", "azure", "file"

  s3:
    bucket_name: "session-buddy-${USER}"
    endpoint_url: "${S3_ENDPOINT:-}"
    region: "us-west-2"

  gcs:
    bucket_name: "session-buddy-${USER}"
    project: "${GCP_PROJECT_ID}"

  azure:
    account_name: "${AZURE_ACCOUNT_NAME}"
    container: "session-buddy"

  file:
    local_path: "~/.claude/data/sessions"

# Local Cache (always enabled)
database_path: "~/.claude/data/reflection.duckdb"

# Memory Aggregation
aggregation_enabled: true
sync_interval: 60
```

---

## Part 8: Testing Strategy

### Test Coverage Requirements

- **Unit Tests**: 80%+ coverage per module
- **Integration Tests**: Full workflow coverage
- **Property-Based Tests**: Critical logic (Hypothesis)
- **Performance Tests**: 10+ repos, 100+ concurrent operations

### Test Organization

```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_code_index_service.py
â”‚   â”œâ”€â”€ test_ssh_worker.py
â”‚   â”œâ”€â”€ test_mqtt_worker.py
â”‚   â”œâ”€â”€ test_terminal_worker.py
â”‚   â”œâ”€â”€ test_container_worker.py
â”‚   â”œâ”€â”€ test_database_worker.py
â”‚   â””â”€â”€ test_backup_worker.py
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_code_index_e2e.py
â”‚   â”œâ”€â”€ test_ssh_workflow.py
â”‚   â”œâ”€â”€ test_mqtt_iot_scenario.py
â”‚   â”œâ”€â”€ test_container_deployment.py
â”‚   â””â”€â”€ test_memory_aggregation.py
â”œâ”€â”€ property/
â”‚   â”œâ”€â”€ test_code_index_properties.py
â”‚   â””â”€â”€ test_worker_properties.py
â””â”€â”€ performance/
    â”œâ”€â”€ test_code_index_scalability.py
    â””â”€â”€ test_worker_concurrency.py
```

### Test Examples

#### Unit Test: SSH Worker

```python
@pytest.mark.unit
async def test_ssh_worker_non_interactive_execution():
    """Test non-interactive SSH command execution."""
    worker = SSHWorker(host="localhost", username="test")
    result = await worker.execute(command="echo 'Hello, World!'")

    assert result.exit_code == 0
    assert "Hello, World!" in result.output
    assert result.status == WorkerStatus.COMPLETED
```

#### Integration Test: Code Indexing

```python
@pytest.mark.integration
@pytest.mark.asyncio
async def test_full_code_indexing_workflow():
    """Git commit â†’ poll â†’ index â†’ cache â†’ event â†’ Session-Buddy."""
    # Make git commit
    await make_test_commit(repo_path)

    # Start polling
    service = CodeIndexService(app)
    await service.start_git_polling()

    # Wait for indexing (max 60s)
    await asyncio.sleep(35)

    # Verify cache
    cache = SQLiteCodeCache()
    graph = await cache.load_graph(repo_path)
    assert graph is not None

    # Verify event published
    events = await message_bus.get_published_events("code.graph.indexed")
    assert len(events) > 0
    assert events[-1]["data"]["repo"] == str(repo_path)
```

#### Property-Based Test: Git Polling

```python
@pytest.mark.property
@given(st.lists(st.text(min_size=1), min_size=1, max_size=100))
async def test_git_polling_jitter_distribution(repo_paths):
    """Verify jitter prevents thundering herd."""
    service = CodeIndexService(app)
    jitters = [service._calculate_jitter(Path(p)) for p in repo_paths]

    # Verify jitters are distributed (not all the same)
    assert len(set(jitters)) > len(jitters) * 0.8  # 80% unique

    # Verify jitter range is 0-5 seconds
    assert all(0 <= j <= 5.0 for j in jitters)
```

#### Performance Test: Concurrent SSH

```python
@pytest.mark.performance
@pytest.mark.asyncio
async def test_ssh_concurrent_connections():
    """Test 100 concurrent SSH connections complete in <30s."""
    worker = SSHWorker(host="localhost", username="test")

    start_time = asyncio.get_event_loop().time()
    tasks = [worker.execute(command="sleep 1") for _ in range(100)]
    results = await asyncio.gather(*tasks)
    duration = asyncio.get_event_loop().time() - start_time

    assert duration < 30.0  # 100 concurrent sleeps should finish in ~5s
    assert all(r.exit_code == 0 for r in results)
```

---

## Summary

### Unified Plan Components

1. **Code Indexing Architecture** (9-13 days)
   - Git polling service (scalable to 100+ repos)
   - SQLite caching for fast startup
   - Event-driven integration via message bus
   - ADR 003 error handling (retry, CB, DLQ)

2. **Session-Buddy Memory Strategy** (5 days)
   - Hybrid: Local DuckDB + cloud S3/GCS/Azure
   - Each worker has local cache for speed
   - All workers push to shared cloud storage
   - Akosha pulls from cloud for analytics

3. **Worker Expansion** (15-20 days)
   - SSH/SFTP worker (asyncssh, PTY support)
   - MQTT worker (gmqtt, IoT edge scenarios)
   - Interactive Terminal worker (PTY allocation)
   - Docker/Cloud Run worker (buildpacks, serverless)
   - Database worker (multi-dialect: PostgreSQL, MySQL, SQLite)
   - Backup worker (automated backups, restore)

4. **Multi-Agent Review Strategy** (baked into workflow)
   - Architecture review (design phase)
   - Security review (pre-implementation)
   - Operations review (pre-deployment)
   - Trifecta review (final GO/NO-GO)

### Overall Timeline

**5-7 weeks** for complete system including all multi-agent reviews and hardening

### Architecture Scores (Post-Review)

| Component | Score | Status |
|-----------|-------|--------|
| Code Indexing | 9/10 | âœ… Scalable, event-driven, ADR compliant |
| Memory Strategy | 9.5/10 | âœ… Fast, resilient, cost-effective |
| Worker Expansion | 8.5/10 | âœ… Comprehensive, async-native |
| Security | 6.5/10 | ğŸ”´ Needs P0/P1 remediation |
| Operations | 6.5/10 | ğŸ”´ Needs monitoring, SLOs |

**Overall Score: 8.5/10** (with remediation plan included)

### Next Steps

1. **Address P0 security issues** (Week 1)
   - Implement SQLCipher for encrypted SQLite
   - Add `@require_auth` to all code index tools
   - Enable S3 SSE-KMS for cloud storage

2. **Start Phase 1 implementation** (Week 1-2)
   - CodeIndexService with git polling
   - Add jittered polling intervals
   - Implement EventBus (system-wide, persistent)

3. **Continue phased implementation** (Week 2-7)
   - Follow timeline in Part 5
   - Conduct multi-agent reviews at each phase
   - Update this document with progress

---

**Document Status:** âœ… Ready for Implementation
**Last Updated:** 2025-02-03
**Next Review:** After Phase 0 completion (estimated 2025-02-10)
